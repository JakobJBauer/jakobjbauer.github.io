---
title: "Neuro-Symbolic Visual Graph Question Answering with LLMs for Language Parsing"
collection: publications
category: #manuscripts
permalink: /publication/2023-11-21_VGQA
excerpt: 'We present a new VQA dataset for graph-based images and a neuro-symbolic model achieving 73% accuracy.'
date: 2023-11-21
venue: 'TAASP 2023'
slidesurl: #'http://academicpages.github.io/files/slides1.pdf'
paperurl: 'http://www.kr.tuwien.ac.at/events/taasp23/papers/TAASP_2023_paper_3.pdf'
citation: #'Your Name, You. (2009). &quot;Paper Title Number 1.&quot; <i>Journal 1</i>. 1(1).'
---

Images containing graph-based structures are an ubiquitous and popular form of data representation that, to the best of our knowledge, have not yet been considered in the domain of Visual Question Answering (VQA). We provide a respective novel dataset and present a modular neuro-symbolic approach as a first baseline. Our dataset extends CLEGR, an existing dataset for question answering on graphs inspired by metro networks. Notably, the graphs there are given in symbolic form, while we consider the more challenging problem of taking images of graphs as input. Our solution combines optical graph recognition for graph parsing, a pre-trained optical character recognition neural network for parsing node labels, and answer-set programming for reasoning. The model achieves an overall average accuracy of 73% on the dataset. While regular expressions are sufficient to parse the natural language questions, we also study various large-language models to obtain a more robust solution that also generalises well to variants of questions that are not part of the dataset. Our evaluation provides further evidence of the potential of modular neuro-symbolic systems, in particular with pre-trained models, to solve complex VQA tasks. 